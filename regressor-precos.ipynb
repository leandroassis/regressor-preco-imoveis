{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b68064d",
   "metadata": {},
   "source": [
    "# Relatório 2 - Regressao Multivariável\n",
    "\n",
    "##  Estimar o preço de um imóvel a partir de suas características\n",
    "\n",
    "### Aluno: Leandro Assis dos Santos - DRE 120032476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d342dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas utilziadas ao longo do projeto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import pearsonr\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49bf4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos conjutos de amostras\n",
    "dados_treino = pd.read_csv(\"conjunto_de_treinamento.csv\", delimiter=\",\", decimal=\".\")\n",
    "dados_teste = pd.read_csv(\"conjunto_de_teste.csv\", delimiter=\",\", decimal=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca0bf8",
   "metadata": {},
   "source": [
    "# Análise dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c74c8",
   "metadata": {},
   "source": [
    "Primeiramente faz-se uma análise dos dados e de seus significados a fim de entende-los e idealizar possíveis ajustes e modelos que se adequariam ao mesmos. Para essa análise, fez-se a visualização dos conjuntos de treino e teste como tabela e os dos gráficos das variáveis em relação ao alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8c898",
   "metadata": {},
   "source": [
    "## Análise dos conjuntos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed37aa",
   "metadata": {},
   "source": [
    "Através da análise das tabelas é possível notar que existem dados categóricos (Ex. colunas \"bairro\", \"tipo\" e etc) que deverão ser convertidos em valores numéricos futuramente. É notável também que a coluna \"diferenciais\" apresenta dados redundantes, uma vez que lista dados que já são apresentados nas colunas posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2168d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc5d4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados_teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328c170",
   "metadata": {},
   "source": [
    "## Análise dos gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d451a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# para ver os gráficos basta descomentar as linhas seguintes\n",
    "#for coluna in dados_treino.columns:\n",
    "#     dados_treino.plot.scatter(x=coluna, y='preco')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc48fc",
   "metadata": {},
   "source": [
    "Para aprofundar o entendimento quanto às características do conjunto de dados gerou-se os gráficos de cada variável em relação com o alvo. Foi possível perceber alguns outliers nas colunas \"area_util\", \"area_extra\" e \"vagas\", já que imóveis cadastrados com quantidades muito acima da média possuiam preços ridiculamente baixos. Os outliers serão tratados futuramente no decorrer do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4728c7",
   "metadata": {},
   "source": [
    "Através da análise dos gráficos é possível identificar a correlação de algumas variáveis com o alvo. Dentre elas destacam-se as colunas \"quartos\" e \"suites\" que, assim como esperado, apresentam uma correlação positiva forte com o preço final do imóvel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ec8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_com_outliers = ['area_util', 'area_extra', 'vagas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5f41a",
   "metadata": {},
   "source": [
    "# Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f732e5e",
   "metadata": {},
   "source": [
    "Após entender como os dados se comportam e identificar tratamentos e conversões que devem ser feitas no conjunto de dados, faz-se os seguintes processos para limpar os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2403ca",
   "metadata": {},
   "source": [
    "## Remoção de colunas e conversão de variáveis não numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b796a99",
   "metadata": {},
   "source": [
    "Nesta etapa remove-se as colunas \"Id\" e \"diferenciais\" que foram julgadas como irrelevantes para a predição do modelo. Além disso, troca-se a informação sobre os bairros da coluna \"bairro\" pela classificação arbitrária em relação ao preço médio das casas em determinado bairro. Determinado bairro pode ser classificado como \"pobre\", \"mediano\", \"normal\", \"bom\", \"luxo\", \"5_estrelas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed842387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id - remover\n",
    "# tipo, tipo_vendedor - get_dummies\n",
    "# bairro - transformar em preço_medio do bairro > x vezes a media dos imoveis\n",
    "# vagas - tirar outliers\n",
    "# area_util - tirar outliers\n",
    "# area_extra - tirar outliers\n",
    "# diferenciais - remover \n",
    "\n",
    "dados_treino = dados_treino.drop(columns=['Id', 'diferenciais'])\n",
    "dados_teste = dados_teste.drop(columns=['Id', 'diferenciais'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc6d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_imoveis = dados_treino['preco'].mean()\n",
    "\n",
    "def classifica_bairros(df):\n",
    "    classificacao_bairros = {}\n",
    "\n",
    "    for bairro in df['bairro']:\n",
    "        media_preco = dados_treino[dados_treino['bairro'] == bairro]['preco'].mean()\n",
    "\n",
    "        if media_preco <= media_imoveis/6:\n",
    "            classificacao_bairros[bairro] = 'pobre'\n",
    "        elif media_preco <= media_imoveis/3:\n",
    "            classificacao_bairros[bairro] = 'mediano'\n",
    "        elif media_preco <= media_imoveis:\n",
    "            classificacao_bairros[bairro] = 'normal'\n",
    "        elif media_preco >= media_imoveis*3:\n",
    "            classificacao_bairros[bairro] = '5_estrelas'\n",
    "        elif media_preco >= media_imoveis*1.5:\n",
    "            classificacao_bairros[bairro] = 'luxo'\n",
    "        elif media_preco >= media_imoveis:\n",
    "            classificacao_bairros[bairro] = 'bom'\n",
    "\n",
    "    return classificacao_bairros\n",
    "\n",
    "dados_teste['bairro'] = dados_teste['bairro'].map(classifica_bairros(dados_teste))\n",
    "dados_treino['bairro'] = dados_treino['bairro'].map(classifica_bairros(dados_treino))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05634f73",
   "metadata": {},
   "source": [
    "## Substituindo valores NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad974e",
   "metadata": {},
   "source": [
    "Após converter todos os dados da coluna bairro, verifica-se a existência de algum bairro no conjunto de teste que não existia no conjunto de treino. Essa tarefa é simplificada pois, no trecho de código acima, caso o bairro não fosse encontrado no conjunto de treino, seria preenchido como NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ffcf317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados NULL por coluna no conjunto de treino\n",
      "tipo              0\n",
      "bairro            0\n",
      "tipo_vendedor     0\n",
      "quartos           0\n",
      "suites            0\n",
      "vagas             0\n",
      "area_util         0\n",
      "area_extra        0\n",
      "churrasqueira     0\n",
      "estacionamento    0\n",
      "piscina           0\n",
      "playground        0\n",
      "quadra            0\n",
      "s_festas          0\n",
      "s_jogos           0\n",
      "s_ginastica       0\n",
      "sauna             0\n",
      "vista_mar         0\n",
      "preco             0\n",
      "dtype: int64\n",
      "\n",
      "Dados NULL por coluna no conjunto de teste\n",
      "tipo              0\n",
      "bairro            4\n",
      "tipo_vendedor     0\n",
      "quartos           0\n",
      "suites            0\n",
      "vagas             0\n",
      "area_util         0\n",
      "area_extra        0\n",
      "churrasqueira     0\n",
      "estacionamento    0\n",
      "piscina           0\n",
      "playground        0\n",
      "quadra            0\n",
      "s_festas          0\n",
      "s_jogos           0\n",
      "s_ginastica       0\n",
      "sauna             0\n",
      "vista_mar         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dados NULL por coluna no conjunto de treino\")\n",
    "print(dados_treino.isnull().sum(), end='\\n\\n')\n",
    "print(\"Dados NULL por coluna no conjunto de teste\")\n",
    "print(dados_teste.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334532e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste[['bairro']] = dados_teste[['bairro']].fillna('normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec43bcc",
   "metadata": {},
   "source": [
    "Após executar a célula anterior, é garantido que todas as colunas de ambos os conjuntos de dados estão preenchidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e12d8",
   "metadata": {},
   "source": [
    "## Splitando variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e466a7d",
   "metadata": {},
   "source": [
    "Como foi percebido durante a análise de dados, é necessário converter as variáveis categóricas em variáveis booleanas. Para isso utiliza-se a função get_dummies abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8674a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_a_trocar = ['tipo', 'tipo_vendedor', 'bairro']\n",
    "\n",
    "dados_treino = pd.get_dummies(dados_treino, columns=valores_a_trocar)\n",
    "dados_teste = pd.get_dummies(dados_teste, columns=valores_a_trocar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3563b",
   "metadata": {},
   "source": [
    "Existe um imóvel no conjunto de treino pertencente a um tipo que não existe no conjunto de teste, isso resulta em uma coluna a mais no conjunto de treino após o get_dummies. Para lidar com isso, cria-se a referida coluna no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8ecd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste['tipo_Quitinete'] = [0 for indice in range(len(dados_teste))] # cria uma coluna em dados_teste que não existia\n",
    "dados_teste['bairro_pobre'] = [0 for indice in range(len(dados_teste))] # cria uma coluna em dados_teste que não existia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc76ab",
   "metadata": {},
   "source": [
    "## Removendo Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b037d9",
   "metadata": {},
   "source": [
    "Como discutido em sala de aula e por recomendação do professor, remove-se os outliers de preõ do conjunto de treino. Porém, como percebido durante a análise dos gráficos, existem outras variáveis que apresentam valores discrepantes. Por conta disso, resolvi passar um filtro em todas as colunas com outliers visíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8d4d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove as samples que possuem alvo > 10M ou alvo < 50K\n",
    "dados_treino = dados_treino[(dados_treino['preco'] > 50000)&(dados_treino['preco'] < 10000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ddb9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte todas as colunas para float a fim de poder fazer comparações aritméticas\n",
    "dados_treino = dados_treino.astype(float)\n",
    "dados_teste = dados_teste.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "918b9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitui os valores incompativeis com o valor médio de cada coluna por NaN\n",
    "for coluna in colunas_com_outliers:\n",
    "    Q1 = np.percentile(dados_treino[coluna], 25,\n",
    "                   method = 'midpoint')\n",
    " \n",
    "    Q3 = np.percentile(dados_treino[coluna], 75,\n",
    "                   method = 'midpoint')\n",
    "    IQR = Q3 - Q1\n",
    " \n",
    "    max_ = Q3+1.5*IQR\n",
    "    min_ = Q1-1.5*IQR\n",
    "    \n",
    " \n",
    "    dados_treino.loc[dados_treino[coluna] < min_, coluna] = np.nan\n",
    "    dados_treino.loc[dados_treino[coluna] > max_, coluna] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56d2f8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quartos                          0\n",
       "suites                           0\n",
       "vagas                          191\n",
       "area_util                      245\n",
       "area_extra                     549\n",
       "churrasqueira                    0\n",
       "estacionamento                   0\n",
       "piscina                          0\n",
       "playground                       0\n",
       "quadra                           0\n",
       "s_festas                         0\n",
       "s_jogos                          0\n",
       "s_ginastica                      0\n",
       "sauna                            0\n",
       "vista_mar                        0\n",
       "preco                            0\n",
       "tipo_Apartamento                 0\n",
       "tipo_Casa                        0\n",
       "tipo_Loft                        0\n",
       "tipo_Quitinete                   0\n",
       "tipo_vendedor_Imobiliaria        0\n",
       "tipo_vendedor_Pessoa Fisica      0\n",
       "bairro_5_estrelas                0\n",
       "bairro_bom                       0\n",
       "bairro_luxo                      0\n",
       "bairro_mediano                   0\n",
       "bairro_normal                    0\n",
       "bairro_pobre                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b26beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preenche os dados NaN gerados pela remoção dos outliers com a média da coluna\n",
    "for coluna in colunas_com_outliers:\n",
    "    dados_treino[[coluna]] = dados_treino[[coluna]].fillna(dados_treino[coluna].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d32dceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados limpos pós filtragem de outliers\n",
    "#dados_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c83e4",
   "metadata": {},
   "source": [
    "## Análise da correlação das variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92633a7b",
   "metadata": {},
   "source": [
    "Neste ponto todas as variáveis já estão em valores numéricos e é possível verificar numericamente a correlação de cada uma com o alvo. Nas células seguintes, calcula-se e apresenta-se de forma ordenada o módulo do coeficiente de Pearson para cada variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a23ab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\assis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['quadra', 0.0027],\n",
       " ['s_ginastica', 0.003],\n",
       " ['bairro_pobre', 0.0133],\n",
       " ['s_jogos', 0.0137],\n",
       " ['tipo_Loft', 0.0153],\n",
       " ['tipo_Quitinete', 0.0182],\n",
       " ['tipo_vendedor_Imobiliaria', 0.0297],\n",
       " ['tipo_vendedor_Pessoa Fisica', 0.0297],\n",
       " ['estacionamento', 0.0452],\n",
       " ['churrasqueira', 0.046],\n",
       " ['bairro_normal', 0.0469],\n",
       " ['playground', 0.0538],\n",
       " ['bairro_luxo', 0.0609],\n",
       " ['s_festas', 0.0695],\n",
       " ['piscina', 0.0778],\n",
       " ['tipo_Apartamento', 0.1032],\n",
       " ['tipo_Casa', 0.1086],\n",
       " ['bairro_5_estrelas', 0.1194],\n",
       " ['sauna', 0.1377],\n",
       " ['bairro_mediano', 0.1449],\n",
       " ['bairro_bom', 0.1685],\n",
       " ['vista_mar', 0.1919],\n",
       " ['vagas', 0.3792],\n",
       " ['area_util', 0.4852],\n",
       " ['quartos', 0.564],\n",
       " ['suites', 0.6867],\n",
       " ['preco', 1.0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcula o coeficiente de Pearson para cada coluna em relação ao alvo\n",
    "pearson_coef = {}\n",
    "\n",
    "for coluna in dados_treino.columns:\n",
    "    coef = round(abs(pearsonr(dados_treino[coluna], dados_treino['preco'])[0]),4)\n",
    "    if type(coef) not in [float, int] or coluna == 'preco':\n",
    "        pearson_coef[coluna] = coef\n",
    "        \n",
    "from operator import itemgetter\n",
    "\n",
    "coef_ordenados = sorted(pearson_coef.items(), key=itemgetter(1))\n",
    "\n",
    "coef_ordenados = [[tupla[0], tupla[1]] for tupla in coef_ordenados]\n",
    "\n",
    "coef_ordenados = sorted(coef_ordenados, key=itemgetter(1))\n",
    "coef_ordenados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad7a51",
   "metadata": {},
   "source": [
    "Com os coeficientes numéricos listados acima, pode-se escolher manualmente as variáveis com maior correlação para compor  o modelo preditivo. Entretanto para diferenciar do realizado no Trabalho 1 e, dado a pequena quantidade de variáveis (e a presença de coeficientes muito mais relevantes na maioria em comparação ao Trabalho anterior), decidiu-se deixar a decisão da escolha de variáveis para um dos métodos de feature selection implementados na biblioteca sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a4e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_aceitavel = 0 # todas as variaveis que possuem Pearson não nulo\n",
    "variaveis_escolhidas = []\n",
    "\n",
    "for item in coef_ordenados[indice_aceitavel:]:\n",
    "    variaveis_escolhidas.append(item[0])\n",
    "\n",
    "dados_treino = dados_treino[variaveis_escolhidas]\n",
    "dados_teste = dados_teste[variaveis_escolhidas[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7751a",
   "metadata": {},
   "source": [
    "## Separação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "794f6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separacao do conjunto de treino em alvo e features\n",
    "X = dados_treino.drop(columns=['preco'])\n",
    "Y = np.array(dados_treino['preco'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a4500",
   "metadata": {},
   "source": [
    "## Escalando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a042e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalando os dados\n",
    "standard_scaler =  StandardScaler()\n",
    "\n",
    "X = standard_scaler.fit_transform(X)\n",
    "dados_teste = standard_scaler.transform(dados_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b031b",
   "metadata": {},
   "source": [
    "# Escolhendo variáveis e criando os modelos preditivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548bcd5",
   "metadata": {},
   "source": [
    "Dada a natureza do problema resolvi utilizar dois modelos combinados, KNN e Random Forest. Ambos os modelos foram calibrados e metrificados incontáveis vezes até obter uma configuração de hiperparâmetros satisfatória.\n",
    "\n",
    "A avaliação dos modelos é feita através de validação cruzada (utilizando o módulo KFold), para cada validação é computado o RMSPE da configuração de modelo naquele determinado subconjunto de dados. Ao final da última validação, é computada a média do RMSPE da configuração. A configuração com menor RMSPE médio foi escolhida para compor o modelo final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad5195",
   "metadata": {},
   "source": [
    "Para escolher as variáveis foi utilizado a função SequentialFeatureSelector que computa um algoritmo greedy a fim de obter a melhor combinação de features do conjunto de dados. O ajuste do \"n_features_to_select\" foi feito de forma empírica avaliando a variação no RMSPE médio de cada configuração do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9882236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=1456) # cria instancia utilizada para CV no teste dos modelos\n",
    "\n",
    "def rmspe(y_true, y_pred): # função para calcular o RMSPE \n",
    "    return np.sqrt(np.mean(np.square(((y_true - y_pred) / y_true))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26498de",
   "metadata": {},
   "source": [
    "## Criando KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "164f50c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  K   |    RMSPE   \n",
      "1        0.5106\n",
      "3        0.3917\n",
      "5        0.3646\n",
      "7        0.3678\n"
     ]
    }
   ],
   "source": [
    "print(\"  K   |    RMSPE   \")\n",
    "for numero_kneighbors in range(1, 9, 2):\n",
    "    regressorKNN = KNeighborsRegressor(n_neighbors=numero_kneighbors, weights='uniform')\n",
    "    \n",
    "    sfs = SequentialFeatureSelector(regressorKNN, n_features_to_select=11, direction='backward')\n",
    "    sfs.fit(X, Y)\n",
    "    \n",
    "    erro_percentual_medio = []\n",
    "    for indice_treino, indice_teste in kf.split(X):\n",
    "        regressorKNN.fit(sfs.transform(X[indice_treino]), Y[indice_treino])\n",
    "\n",
    "        predicao = regressorKNN.predict(sfs.transform(X[indice_teste]))\n",
    "        erro_percentual_medio.append(rmspe(predicao, Y[indice_teste]))\n",
    "    \n",
    "    print(  \"%d    \" %numero_kneighbors, end='')\n",
    "    print(f\"    {round(mean(erro_percentual_medio), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393324e3",
   "metadata": {},
   "source": [
    "## Criando Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f3beb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N   |   RMSPE  \n",
      "33      0.3623\n",
      "36      0.3488\n",
      "39      0.3531\n",
      "42      0.349\n"
     ]
    }
   ],
   "source": [
    "print(\"  N   |   RMSPE  \")\n",
    "for numero in range(33, 45, 3):\n",
    "    regressorRF = RandomForestRegressor(n_estimators=numero)\n",
    "     \n",
    "    sfs = SequentialFeatureSelector(regressorRF, n_features_to_select=10, direction='backward')\n",
    "    sfs.fit(X, Y)\n",
    "    \n",
    "    erro_percentual_medio = []\n",
    "    for indice_treino, indice_teste in kf.split(X):\n",
    "        regressorRF.fit(sfs.transform(X[indice_treino]), Y[indice_treino])\n",
    "\n",
    "        predicao = regressorRF.predict(sfs.transform(X[indice_teste]))\n",
    "        erro_percentual_medio.append(rmspe(predicao, Y[indice_teste]))\n",
    "    \n",
    "    print(\"%d    \" %numero, end='')\n",
    "    print(f\"  {round(mean(erro_percentual_medio), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157a73b",
   "metadata": {},
   "source": [
    "## Criando modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027191aa",
   "metadata": {},
   "source": [
    "O modelo final utiliza das predições dos modelos de KNN e Random Forest para calcular suas predições. Basicamente o modelo final calcula a média ponderada entre as n-ésimas predições do KNN e do Random Forest utilizando como pesos o inverso do RMSPE médio calculado durante o fitting do modelo final.\n",
    "\n",
    "O RMSPE médio calculado durante o fitting é a média dos RMSPE calculados em cada validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f1e4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor():\n",
    "    def __init__(self):\n",
    "        self.RFC = RandomForestRegressor(n_estimators=37)\n",
    "        self.KNN = KNeighborsRegressor(n_neighbors=6, weights='uniform')\n",
    "        self.modelos = [self.KNN, self.RFC]\n",
    "    def fit(self, X, Y):\n",
    "        self.rmspe_modelos = []\n",
    "        self.sfs = [SequentialFeatureSelector(self.modelos[0], n_features_to_select=11, direction='backward'), \\\n",
    "                    SequentialFeatureSelector(self.modelos[1], n_features_to_select=10, direction='backward')]\n",
    "        for indice, modelo in enumerate(self.modelos): \n",
    "            self.sfs[indice].fit(X, Y)\n",
    "            self.modelos[indice] = modelo.fit(self.sfs[indice].transform(X), Y)\n",
    "            \n",
    "            erro_percentual_medio = []\n",
    "            for indice_treino, indice_teste in kf.split(X):\n",
    "                modelo.fit(self.sfs[indice].transform(X[indice_treino]), Y[indice_treino])\n",
    "\n",
    "                predicao_teste = modelo.predict(self.sfs[indice].transform(X[indice_teste]))\n",
    "                predicao_treino = modelo.predict(self.sfs[indice].transform(X[indice_treino]))\n",
    "                erro_percentual_medio.append(rmspe(predicao_teste, Y[indice_teste]))\n",
    "            self.rmspe_modelos.append(mean(erro_percentual_medio))\n",
    "    def predict(self, X_alvo):\n",
    "        predicao_modelos = [modelo.predict(self.sfs[indice].transform(X_alvo)) for indice, modelo in enumerate(self.modelos)]\n",
    "        \n",
    "        peso_KNN = 1/self.rmspe_modelos[0]\n",
    "        peso_RFC = 1/self.rmspe_modelos[1]\n",
    "        \n",
    "        return [ (predicao_modelos[0][indice]*peso_KNN + predicao_modelos[1][indice]*peso_RFC)/(peso_RFC+peso_KNN) \\\n",
    "                for indice in range(len(X_alvo))]\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c041670",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Regressor()\n",
    "\n",
    "rmspe_teste = []\n",
    "rmspe_treino = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151c540",
   "metadata": {},
   "source": [
    "## Avaliação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b31e72",
   "metadata": {},
   "source": [
    "Para avaliar o modelo computa-se o RMSPE das previsões para a amostra de treino e teste. Ao final computa-se as médias dos RMSPE para ambas as amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afa0b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TESTE  |  TREINO\n",
      "   0.3866     0.2263\n",
      "   0.2842     0.2533\n",
      "   0.4252     0.2594\n",
      "-------------------\n",
      "  TESTE  |  TREINO\n",
      "   0.3653     0.2463\n"
     ]
    }
   ],
   "source": [
    "# faz a CV do modelo final\n",
    "print(\"  TESTE  |  TREINO\")\n",
    "for indice_treino, indice_teste in kf.split(X):\n",
    "    regressor.fit(X[indice_treino], Y[indice_treino])\n",
    "    yteste = regressor.predict(X[indice_teste])\n",
    "    ytreino = regressor.predict(X[indice_treino])\n",
    "    \n",
    "    score_teste = round(rmspe(yteste, Y[indice_teste]), 4)\n",
    "    score_treino = round(rmspe(ytreino, Y[indice_treino]) ,4)\n",
    "    \n",
    "    rmspe_teste.append(score_teste)\n",
    "    rmspe_treino.append(score_treino)\n",
    "    \n",
    "    print(f\"   {score_teste}     \", end='')\n",
    "    print(score_treino)\n",
    "\n",
    "print(\"-------------------\")\n",
    "print(\"  TESTE  |  TREINO\")\n",
    "print(f\"   {round(mean(rmspe_teste), 4)}     \", end='')\n",
    "print(round(mean(rmspe_treino), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38dd012",
   "metadata": {},
   "source": [
    "# Geração do arquivo de respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94ec0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X, Y)\n",
    "\n",
    "x_resposta = dados_teste\n",
    "\n",
    "y_resposta = regressor.predict(x_resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0207453",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_solicitante = [x for x in range(2000)]\n",
    "\n",
    "dados_resposta = pd.DataFrame(list(zip(id_solicitante, y_resposta)), columns=['Id', 'preco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddbcfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_resposta.to_csv(\"arquivo_resposta.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
